<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Agency - Start Bootstrap Theme</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.3/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top">Timothy L. Carter</a>
                <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars ml-1"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ml-auto">

                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#portfolio">Portfolio</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#career">My Journey</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">Contact</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead">
            <div class="container">
                <div class="masthead-subheading">Data Science</div>
                <div class="masthead-heading text-uppercase">Engineering The Future</div>
                <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="#portfolio">My Portfolio</a>
            </div>
        </header>
        <!-- Activism & Enginneering-->
        <section class="page-section" >
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Activism & Data</h2>
                    <h3 class="section-subheading text-muted">The two go hand in hand! It's all about understanding the need's of your community, 
                        getting to know the data, and developing solutions that change and improve lives. Meaningful sollutions and innovations require collaboration, sound data, and thoughtful design working in unison.</h3>
                </div>
                <div class="row text-center">
                    <div class="col-md-4">
                        <span class="fa-stack fa-4x">
                            <i class="fas fa-circle fa-stack-2x text-primary"></i>
                            <i class="fas fa-comments fa-stack-1x fa-inverse"></i>
                        </span>
                        <h4 class="my-3">Consensus</h4>
                        <p class="text-muted">Consensus-building strengthens relationships between colleagues, as well as clients and service providers, empowering innovative solutions to problems involving many stakeholders. </p>
                    </div>
                    <div class="col-md-4">
                        <span class="fa-stack fa-4x">
                            <i class="fas fa-circle fa-stack-2x text-primary"></i>
                            <i class="fas fa-code fa-stack-1x fa-inverse"></i>
                        </span>
                        <h4 class="my-3">Analysis</h4>
                        <p class="text-muted">The proper collection, processing, and storage of data represent the greater portion of the labor required to make accurate, and insightful statistical analysis possible.</p>
                    </div>
                    <div class="col-md-4">
                        <span class="fa-stack fa-4x">
                            <i class="fas fa-circle fa-stack-2x text-primary"></i>
                            <i class="fas fa-cogs fa-stack-1x fa-inverse"></i>
                        </span>
                        <h4 class="my-3">Design</h4>
                        <p class="text-muted">Good design is about more than having an aestheticly pleasing or functional product. It's about creating an experience that is intuitive, enjoyable, and benificial to the users.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- Portfolio Grid-->
        <section class="page-section bg-light" id="portfolio">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Portfolio</h2>
                    <h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3>
                </div>
                <div class="row">
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal1">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="assets/img/portfolio/final_model.png" alt="..." />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Topic Modeling & Sentiment Analysis</div>
                                <div class="portfolio-caption-subheading text-muted">Web-Scrapping Social Media Content</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal2">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="assets/img/portfolio/Post Lenght Density.png" alt="..." />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Binary Classification & Pipelines</div>
                                <div class="portfolio-caption-subheading text-muted">Determining Fact From Fiction</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal3">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="assets/img/portfolio/Predictions Vs Reality.png" alt="..." />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Feature Selection & Multicollinearity</div>
                                <div class="portfolio-caption-subheading text-muted">Predicting Home Sale Prices</div>
                            </div>
                        </div>
                    </div>
                   
                    
        </section>
        <!-- About-->
        <section class="page-section" id="career">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">My Journey</h2>
                    <h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3>
                </div>
                <ul class="timeline">
                    <li>
                        <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/YAB3.jpg" alt="..." /></div>
                        <div class="timeline-panel">
                            <div class="timeline-heading">
                                <h4>2011-2012</h4>
                                <h4 class="subheading"> Pennsylvania Youth Adivsory Board Regional President</h4>
                            </div>
                            <div class="timeline-body"><p class="text-muted"> Working with thousands of foster youth from across the state in partnership with teams of dedicated lawyers and social workers, I oversaw regional campaigns focused on extending the age of foster youth in the state of P.A. eligibility for services post care. Since 2012, foster youth have been able to receive services until the age of 21.
                                <a href='https://jlc.org/act-80-and-act-91-faqs-basics/fostering-connections-basics-act-91-and-act-80'> Act 80 & 91</a> </p></div>
                        </div>
                    </li>
                    
                    <li class="timeline-inverted">
                        <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/epic1.jpg" alt="..." /></div>
                        <div class="timeline-panel">
                            <div class="timeline-heading">
                                <h4>2014</h4>
                                <h4 class="subheading">Organized & Produced an Epic Adventure</h4>
                            </div>
                            <div class="timeline-body"><p class="text-muted"> What would become an annual favorite in the Baltimore are for 4 years running,<a href='https://www.facebook.com/Epic-Adventure-1582739725337536/photos/1770644199880420'> Epic Adventure</a>, co-produced with Paradox Entertainment and organized by yours truelly, was the largest and most succesful event that I helped to host during my time as an events coordinator. Though it may not seem relevant at first, this is where I found my passion for organizing, bringing communities together, and empowering others to share their ideas. </p></div>
                        </div>
                    </li>

                    <li>
                        <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/4.jpg" alt="..." /></div>
                        <div class="timeline-panel">
                            <div class="timeline-heading">
                                <h4>Summer 2015</h4>
                                <h4 class="subheading">A Career in Activism</h4>
                            </div>
                            <div class="timeline-body"><p class="text-muted">My first experience in grassroot's non-profit organizing. Leaving the world of music and entertainment for conferencing and expo's 
                                imporved my salary and lifestyle, but the work brought me little joy. As an outlet I began volunteering my time with 
                                <a href = 'https://secure.foodandwaterwatch.org/donate/als-fight-climate-change?ms=onad_aw_04072020_als-brand-sem&oms=onad_aw_04072020_als-brand-sem&gclid=Cj0KCQjwkZiFBhD9ARIsAGxFX8Chst89YhSpCVNtbzFR-sf_9g7TbTdgPHMoNBxQ7etE9C2dQ8-iRX0aAtnvEALw_wcB'> 
                                    Food & Water Watch </a>, to protect Colorado Communities from air and water pollution. Here again I found my passion, 
                                    this time for empowering communities with the data and decorum to resolve tense and important issues. 
                                    By the end of that first campaing I'd made permanent changes to my career tajectory! </p></div>
                        </div>
                    </li>

                    <li class="timeline-inverted">
                        <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/bears_ears_1.jpg" alt="..." /></div>
                        <div class="timeline-panel">
                            <div class="timeline-heading">
                                <h4>2017</h4>
                                <h4 class="subheading">Defending Public Lands</h4>
                            </div>
                            <div class="timeline-body"><p class="text-muted">As Field Operations Lead for the <a href= 'https://copirg.org/'>Colorado Public Interest Group (COPIRG) </a> 
                                I coordinated and executed a statewide campaign in which myself and a team of a dozen others spoke with over 100,000 registered colorado voters from every voting district and populace living 
                                center in the state. We discussed national and local level issues with individuals of all walks of life, succesfully fundraising 250,000$ in small donor dollars for public health intitiatives. 
                                Though one would not expect it, as our lodgnings throughout the campaing were a hammock or tent of our own selection, this was my first real exposure to the power and promise of data analytics. 
                                Comprehensive memebrship histories, precious campaing performance metrics, and patterns in demographics were just a few of the tools we used when devopin our daily and weekly strategic field plans. </p></div>
                        </div>
                    </li>

                    <li>
                        <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/copirg2.jpg" alt="..." /></div>
                        <div class="timeline-panel">
                            <div class="timeline-heading">
                                <h4>2018</h4>
                                <h4 class="subheading">Campaign Foundations Director</h4>
                            </div>
                            <div class="timeline-body"><p class="text-muted">A few short years into my career in grasroots organizing and I was directing regional campaigns of my own. 
                                As Foundations Director I managed all campaign logistics, analytics, and reporting, while growing a capable team of emloyees and volunteers to consistenlty exceed 
                                campaing fundraising and petition goals. I was solely responsible for the accurate and timely reporting of all regional campaing fincials, and learned skills in 
                                data driven strategic field planning from long time industry experts. Durring my time with COPIRG and <a href='https://publicinterestnetwork.org/'>The Public interest Group</a> 
                                I consistenlty recruited, trained, and supervised teams over 30 capable, motivated, and enthusiastic employees, and countless more volunteers. Having honed my skills in persuasive communication, 
                                I found myself drawn more and more to the data that drove the our stretegic decisions, and backed our most powerful arguments.  
                            </p></div>
                        </div>
                    </li>

                    <li class="timeline-inverted">
                        <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/gas1.jpg" alt="..." /></div>
                        <div class="timeline-panel">
                            <div class="timeline-heading">
                                <h4>2019</h4>
                                <h4 class="subheading">Electrifying Public Infrastructure</h4>
                            </div>
                            <div class="timeline-body"><p class="text-muted">After years of research and litigation, we succeeded not only in holding Volkswagon accountable for the public 
                                health violations incurred durring their TDI fraud first exposed in 2015, but also in securing 20% of the $68 million in damages 
                                awarded to the state of Colorado for electrifying both public and private infrastructure. The achievement I am most proud of, is succesfully implementing 
                                polocy to electrify Public School busses in Colorado, saving scools millions a year in diesel costs, freeing up that revenue to help Colorado's underfunded schools 
                                that struggle with being understaffed, and cope with an abbreviated school week in much of the state. <a href='https://gazette.com/environmental-groups-cheer-plan-to-spend-vw-settlement-dollars-on-green-transportation/article_f69d511c-92c4-5863-bf95-9b4c550efb0d.html'>See more...</a> </p></div>
                        </div>
                    </li>

                    <li class="timeline-inverted">
                        <div class="timeline-image">
                            <h4>
                                Be Part
                                <br />
                                Of My
                                <br />
                                Story!
                            </h4>
                        </div>
                    </li>
                </ul>
            </div>

        </section>
    
        
        <!-- Contact Me -->
        <section class="page-section" id="contact">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Contact Me</h2>
                    <h3 class="section-subheading text-muted">Have questions about my previous work, think I would make a good fit 
                        for your team, or just want to chat about Data Science? Contact me through one of my social media below!
                    </h3>
                </div>
                <div class="container text-center">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/me2.png" alt="..." />
                            <h4 class= 'section-heading label-primary'>Timothy Carter</h4>
                            <p class="text-muted">Data Scientist & Campaign Coordinator</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://twitter.com/TimothyL_Carter"><i class="fab fa-twitter"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.facebook.com/timothycarter12493/"><i class="fab fa-facebook-f"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/timothy-carter-2a4a361a9/"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>

        </section>

        <!-- Skills-->
        <div class="py-5">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-md-3 col-sm-6 my-3">
                        <a href="#!"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/pandas.jpg" alt="..." /></a>
                    </div>
                    <div class="col-md-3 col-sm-6 my-3">
                        <a href="#!"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/SQL.jpg" alt="..." /></a>
                    </div>
                    <div class="col-md-3 col-sm-6 my-3">
                        <a href="#!"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/scikit-learn.jpg" alt="..." /></a>
                    </div>
                    <div class="col-md-3 col-sm-6 my-3">
                        <a href="#!"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/Pyspark.jpg" alt="..." /></a>
                    </div>
                    <div class="col-md-3 col-sm-6 my-3">
                        <a href="#!"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/Tensor.jpg" alt="..." /></a>
                    </div>
                    <div class="col-md-3 col-sm-6 my-3">
                        <a href="#!"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/python.jpg" alt="..." /></a>
                    </div>
                </div>
            </div>
        </div>
    
        <!-- Portfolio Modals-->
        <!-- Modal 1-->
        <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Topic Modeling & Simple Sentiment </h2>
                                    <p class="item-intro text-muted"> With Applications and Suggestions for Targeted Campaigns.</p>
                                    <p class = 'text-uppercase'>Inroduction</p>
                                    <p> The goal of this project was to explore applications of Latent Dirichlet Allocations 
                                        and Simple Sentiment Analysis in targeted issues based policy campaigns. The issue I chose 
                                        as a demonstration of these methods is that of homelessness. The dataset created for this 
                                        project is composed of user posts and comments scrapped from the social media site Nextdoor.com. 
                                        The size of the dataset was limited by a lack of volunteer accounts in varied regions of Denver, 
                                        and a limitation in accessing historical data from the source. The final size of the dataset 
                                        before post-scrape and pre-preprocessing and cleaning, was just above 1,000 posts and 15,000 comments. 
                                        The goal was to apply LDA in order to correlate the sentiment of user posts with their topical 
                                        content. Below is an example of our models final output for the broad topic of homelessness nearly as envisioned.</p>
                                  
                                        <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/Authors.png" alt="..." />
                                        <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/Locations.png" alt="..." />    
                                    <p>Next-door has no public API that we could find. Their web interface is also Javascript heavy making selenium our 
                                        preferred choice of web scraping library for this application. Next-door provides a unique source of textual data 
                                        to other social media sources in several ways. First, users are required to register their physical 
                                        address with legal documentation, providing a greatly increased confidence in the accuracy of recorder 
                                        user geographies. Second, users' access to content is restricted by geography in a way intended to stimulate 
                                        discussions among neighborhood community members, creating a unique virtual landscape full of content pertaining 
                                        to local issues. Unlike other social media outlets, next-doors UIX , or perhaps just their stated mission, seem to 
                                        influence users to provide standard and correctly spelled textual data to a far greater degree than is common with 
                                        Twitter or Reddit for example. Next-door also does not limit the number of characters per post, and so 
                                        posts are significantly longer on average. 
                                    </p>
                                        <p class = 'text-uppercase'>Latent Dirichlet Allocations</p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/LDA_explainer.png" alt="..." />
                                    <p>LDA is an unsupervised machine learning model that allows us to extract descriptive topics 
                                        from textual data. Dirichlet’s are distributions of multinomial distributions represented 
                                        as simplexes. LDA uses two of these distributions , one to represent the distribution of words to topics, 
                                        and the other of topics to words. There are few things our model will need from us before training.
                                        <ul>
                                            <li>Number of expected topics</li>
                                            <li>Alpha - number of expected topics per document</li>
                                            <li>Beta - number of words expected to define each topic</li>
                                        </ul>

                                        The desired output is a list of human readable topics defined both by their most frequently occurring and most relevant terms.
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/final_model.png" alt="..." />
                                    <p>PyLDAvis is a useful library with a singular purpose, the visualization of unsupervised topic 
                                        models. Below is a pyLDAvis example consisting of the result of our homelessness content modeling. 
                                        Topic 1 highlighted in red in actual topic index 0. On the right are the words of which the topic 
                                        is composed. The five most relevant topic terms for topic 0 are help, homeless, need, donate, shelter. 
                                        From this it is left to the modeler to interpret how to define or classify the topic label. In this 
                                        example, I labeled topic 0 as “Homeless - Donations and Shelter”, because their are several topics in our 
                                        dataset pertaining to different aspects of homelessness that we are interested in several of our topic will 
                                        bare the prefix “Homeless” and irrelevant topics should be filtered out by being assigned Misc. as their label.This can be done with a simple python dictionary. </p>
                                    
                                    <p class = 'text-uppercase'>Preprocessing</p>
                                    <p>For topic modeling my dataset I decided to use all post and comment data for training input. 
                                        I constructed my data frame so that each comment has an id# which pertains 
                                        to its originating post. Imagine an example when a post's comments take the topic of 
                                        discussion far from where it began. This happens very often in social media forums. 
                                        We don’t want our pipeline to misrepresent the relationship between the emotional content 
                                        of a post's comments, and the topic of the post, so we include all post and comment data in 
                                        our LDA corpus. While this may mean that our topics appear less applicable to their specific 
                                        posts, they should apply more coherently with the user dialogue encompassed by the post and 
                                        comments combined.
                                        <br><br>
                                        The most significant of the benefits to come from a week's labour building a web scraper was the 
                                        quality and cleanliness with which text was pulled into my initial data frame. I had no line breaks 
                                        to manage, minimal misspellings, and no html tags to clean. I still had to de-accent , lowercase, and inspect 
                                        for token misspellings and acronyms. Something I failed to utilize here was the functionality offered by NLTK’s multiword 
                                        expression tokenizer, which allows for the creation of custom word grams. Using MWE I would focus on domain specific compound 
                                        words and acronyms in order to better inform my model.   
                                        <br><br>
                                        I chose to reduce some of the complexity of the corpus through lemmatization, and by focusing on parts of speech likely to inform the 
                                        topic of the text. For example, conjunctions largely do nothing to inform the topic of a conversation. Since LDA will define our topics 
                                        by the most frequently occurring and relevant terms, we don’t want it getting confused by terms like, ‘and’, ‘but’, ’to’, and others. 
                                        On the other hand, while next-door content is longer on average than that of twitter, I was still dealing with what would be classified as 
                                        short text ( primarily under 150 words ). This being the case, I wanted to refrain from excessively reducing the vocabulary of the corpus. 
                                        To balance these two concerns, nouns, adjectives, verbs, and adverbs were all used in our final topic modeling process.
                                        </p>
                                    <p class = 'text-uppercase'>Grid Search</p> 
                                    <p>Tuning LDA models presents challenges because of its unsupervised nature, and because we are dealing with subjective interpretations 
                                        of  textual data. In this context we don’t have a metric to optimize for, and the metrics we use to evaluate topic models 
                                        don’t really provide insight into the human readability or application of the topical output. Coherence is a measure 
                                        of the semantic similarity between high scoring words within a single topic. This can help us determine which topics are interpretable 
                                        and topics that are merely byproducts of statistical inference. Log perplexity is a measure of the degree to which your model is confused 
                                        by new data. Here a lower well below 0 is desirable, but again we see that this doesn’t measure the actual interpretability of our topics, 
                                        for now, we still need a human for that.
                                        <br><br>
                                        Here is one of several of my creative attempts to visualize model tuning results.
                                    </p>
                                    
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/tunning_results_2-6_topics.png" alt="..." />
                                    <p>The best place to start is by considering the distribution of your topics and words to topics. 
                                        Are the uniform or asymmetrical? For my content, I deduced that since our posts varied quite 
                                        distinctly in length that the number of words in each post which retained to its topic would vary 
                                        significantly, and also that some of my topics would not have the same number of words to define them 
                                        semantically as others ( example: [cat, dog, pet ],[homeless, shelter, volunteer, donate, zoning]) with 
                                        this assumption we expected our model to perform better with the Gensim preset of ‘asymmetrical’ for the beta 
                                        parameter. For alpha, I deduced that the short text and social media orgigins of the text data implied that 
                                        each document likely contained few, if not just one topic per document. 
                                        This too proved to be a useful deduction, as our final alpha parameter was 0.15.
                                        <br><br>
                                        Returning to the hyper parameters I mentioned earlier, Alpha, Beta, and N_topics, I want to add that chunk size, or the 
                                        number of randomly selected documents to include in each successive model training iteration, similar to batch size in 
                                        tensorflow and keras libraries. When working with data other than textual data, the final selection of batch size is often 
                                        the result of a compromise between computational energy usage(ex. image data ) and the overall size of ones dataset 
                                        ( risk : overfitting ).In the case of textual data I found that it the selection of chunk size has a distinctly noticeable 
                                        effect on model output. 
                                        <br><br>
                                        I suggest that other practitioners consider the size of their individual  documents, the degree of 
                                        similarity/dissimilarity of lexicon from document to document in randomly selected samples. For example, 
                                        while training our topic model, we found a small chunk size, and an increased number of training passes to be ideal for 
                                        clarity of model output. Chunksizes less than 60 consistently produced more coherent topics 
                                        while chunk sizes greater than 60 consistently confused the target topic of homelessness with other content. 
                                    </p>
                                    <p class = 'text-uppercase'>Conclusions</p>
                                    <p> While I am happy with that data procured from Next-door, a lack of volunteers and restrictions on searching historical data created a 
                                        shortage of relevant content to work with that caused significant difficulties throughout. Most problematically , I was unable to remove a 
                                        sufficient number of stop words from the corpus to sufficiently clarify the output topics due to the limited size of the model vocabulary.
                                        <br><br>
                                        LDA on its own is a powerful tool to provide insight into the topical content of textual data, however, it has limitations 
                                        on short text that I plan to address in future iterations through the application of Gibbs sampling 
                                        methods. IDA2vec word embeddings would allow our model to utilize bidirectional word embeddings to inform each 
                                        topic as well. 
                                        <br><br>
                                        The results of our model do many accurate classification labels, but with too many inaccuracies to really on for the creation of a labeled dataset. 
                                        To say nothing of the limitations of simple sentiment analysis, the application of which would require creation of a domain specific word count dictionary. 
                                        The output of an LDA model without Gibbs sampling seems to be insufficient for reliable use in targeted campaigns , but a fast 
                                        and easy way to become familiar with the general content of a large corpus. 
                                        </p>
                                    
                                    <ul class="list-inline">
                                        <li>Date: May 2021</li>
                                        <li>Repository: <a href = 'https://github.com/T0admomo/Topic_modeling_LDA_sentiment_Vadar_nextdoor.com'>Github.com</a> </li>
                                        <li>Collaborators: None</li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 2-->
        <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Binary Classficiation of Fact from Fiction</h2>
                                    <p class="item-intro text-muted">Model Selection with Pipelines</p>
                                    <p> The dataset for this project is composed of reddit posts from two distinct subreddit gathered using 
                                        the <a href = 'https://github.com/pushshift/api'>pushshift API</a>. In order to simulate factual and fictional content, we used the r/Fact, 
                                        and r/FakeFact subreddits as sources. Both subreddits are heavily moderated, but neither source is verified. 
                                        We have to assume that some of the Facts, and FakeFacts are out of place, but that will be for my purposes. 
                                        I wanted to teach my model to classify posts based on whether or not their source is a trusted one, not whether or not the post is true. 
                                        The final product will be one of several components in a social media filter intended to block fallacious content. </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/50_50_Reddit.png" alt="..." />
                                        
                                    <p class = 'text-uppercase'>Model Selection</p> 
                                    <p>Initial model selection was conducted using a cleaned corpus deprived of punctuation with no 
                                        stemming or lemmatization. Pipelines can make it simple to train many models consecutively and 
                                        compare their outputs. I constructed several functions available in myfunt.py on the github for 
                                        this project for this purpose that any one is welcome to make use of. I prefer not only to visualize 
                                        test and train performance, but also the gap between test and train for each model while conducting initial model selections. </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/test_train_gap.png" alt="..." />
                                    <p class = 'text-uppercase'> Exploring the Lexicon</p>
                                    <p>Once we had cleaned punctuation and miscellaneous improperly formatted text from our dataset we began to look at the 
                                        overlap in most frequently used words in the lexicons of both subreddits. Our goal here was to isolate the most common words 
                                        shared between both Datasets and remove them from the corpus entirely so as to reduce some dimensionality and increase the 
                                        separation of our two classes. This dramatically reduced the gap between our Train and Test Accuracy Scores, but did little to improve our overall performance.</p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/shared_vocab.png" alt="..." />
                                    <p class = 'text-uppercase'>Feature Engineering</p>
                                    <p>During EDA I noticed that while the post lengths appear to have a similar distribution, the differences in density of factual 
                                        posts with longer text is significant enough for consideration and testing as a feature in our final classification model. The 
                                        final model will take the output from our binary classifier as a feature along with other info like post length, and presence 
                                        of a hyperlink.
                                        <br><br>
                                        30% of the factual posts have links to sources, while only 5 % of the FakeFacts posts had similar links. I have decided to engineer 
                                        a feature for Has_link to include in our final filter model. Assessing the type of link is a step to be explored in a latter phase.
                                        </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/Post Lenght Density.png" alt="..." />
                                    <p class='text-uppercase'>Model Evaluation</p>
                                    <p>Using an AUROC curve we can visualize the performance of multiple models on our cleaned and lexiconicly pruned corpus. In the 
                                        second iteration of this project I will explore the differences in performance when applying stemming vs lemming. The model I 
                                        selected as performing best in this case was Support Vector Machines, as it displayed the smaller train test gap, but Naive Bayes 
                                        is a strong second with a higher score and only slightly larger gap. Given the nature of our dataset and the goal of our model, I only 
                                        really expected to achieve about 80% accuracy with traditional classification models. I am confident with iterative model tuning and additional 
                                        preprocessing either SVM or NB could reach our target accuracy. Using the output from this model as a feature in a future model, along with other features like post length, 
                                        has_link etc. may yet allow us to create an adequate content filter without the computationally expensive use of Neural Networks. </p>

                                    

                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/reddit_results.png" alt="..." />

                                    <ul class="list-inline">
                                        <li>Date: March 2021</li>
                                        <li>Repository: <a href = 'https://github.com/T0admomo/BinaryClassification_fact_fiction_Reddit'>Github.com</a> </li>
                                        <li>Collaborators: None </li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 3-->
        <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Feature Selection & Multicollinearity</h2>
                                    <p class="item-intro text-muted">Predicting Home Sale Prices</p>
                                    <p class = 'text-uppercase'>The Data</p>
                                    <p>The <a href='https://www.kaggle.com/c/house-prices-advanced-regression-techniques'>Ames Housing Data</a> available on Kaggle has been used to create 
                                        many predictive models capable of exceptional performance on the test set. However , the 70 included 
                                        features would make collecting the data necessary for price prediction cumbersome and inefficient. Many of 
                                        the features are categorical qualitative measures that would likely require a professional trained with a 
                                        uniform curriculum to accurately document. So while these 70 feature models display impressive predictive accuracy, 
                                        they aren’t feasibly scalable for most real world uses. 
                                        
                                    </p>
                                    <p class = 'text-uppercase'>Problem</p>
                                    <p>I wanted to explore the features available for those that bore the strongest relationship to sale price so that 
                                        the necessary information to make a prediction required a minimal number of survey questions. 
                                        The questions would ideally require a minimal effort to answer, 
                                        so that any homeowner could apparasie their home for sale in a short period of time.</p>
                                    
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/Heatmap.png" alt="..." />
                                    <p class = 'text-uppercase'>Feature Selection</p>
                                    <p>I began by manufacturing several features from the sq footage data available in order to indicate the presence or absence of 
                                        a garage, a finished basement, and whether or not the lot upon which a property sits is larger than the third percentile. We also 
                                        inspected features like whether or not a home has central air. The feature of square footage need not be engineered, and as one might expect bears 
                                        the strongest apparent relationship to price of all of the 70 initial features. 
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/All_features.jpg" alt="..." />
                                    <p>Each of the above features appear to have a similar relationship to a home's price. Using these features 
                                        and sale price a simple linear regression model achieves an RMSE of nearly 40,000$ which is nearly 30% of the 
                                        average home price, so there's still room for a lot of improvement. Now of course we can add more features, 
                                        but I wanted to stick with the few I had chosen and inspect them further for collinearity. The idea is that I will 
                                        return to the dataset for another feature, but first in order to keep my hypothetical survey short, I want to 
                                        remove any features that fail to inform our model , or that are collinear with our other features. </p>
                                        <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/Predictions Vs Reality.png" alt="..." />
                                    <p class = 'text-uppercase'>Collinearity</p>
                                    <p>
                                        I hear a lot of people struggling with how to deal with collinearity. As one of the vital assumptions in order to perform 
                                        accurate linear regression techniques, non-collinearity in real world datasets can be hard to obtain, and in many cases the 
                                        assumption is treated as one can violate as long as it does not affect the accuracy of the predictive models output. 
                                        However, understanding which of our features are collinear is often the key to reducing model complexity through 
                                        feature engineering, selection, and reduction. 
                                        <br><br>
                                        Plotting kernel density allows us to identify the differences in shape of sale price distributions grouped by our various features. 
                                        Try to examine the shapes of the distributions and guess which of the features I chose to eliminate.
                                        </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/With_features_kde.jpg" alt="..." />
                                    <p>Above , the distributions of sale price by large lot sticks out from the rest, but the other, near identical, will likely not inform the model.</p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/No_features_kde.jpg" alt="..." />
                                    <p>Now which do you think I should remove ?
                                    <br><br>
                                    If you said Garage or Central Air, you have the idea! However, in this case I determined that though the difference between the distributions of the two features in 
                                    our second visualization is slight, I feel it is likely enough to inform our model. For those who couldn’t come up with an educated guess, here is how I made the 
                                    choice. Though the three features “Central Air”,”Garage”, and “Finished basement” don’t appear to inform the model in the first visualization, we can 
                                    see that the shape of sale price distribution among homes that lack these features are more distinct from one another. “No Finished Basement” stands immediately as informative, 
                                    while it could be left to further exploration whether or not “No Garage” and “No A/C” were representing the same information twice. 
                                    </p>
                                    
                                    
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/collaboration.png" alt="..." />
                                    <ul class="list-inline">
                                        <li>Date: April 2021</li>
                                        <li>Repository:<a href = 'https://github.com/T0admomo/Price_prediction_linear_regression_ames'>Github.com</a> </li>
                                        <li>Callaborators: None</li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 4-->
        <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Coming Soon</h2>
                                    <p class="item-intro text-muted">Nothing yet. Check back latter!</p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/04-full.jpg" alt="..." />
                                    <p>Use this area to describe your project. Lorem ipsum dolor sit amet, consectetur adipisicing elit. Est blanditiis dolorem culpa incidunt minus dignissimos deserunt repellat aperiam quasi sunt officia expedita beatae cupiditate, maiores repudiandae, nostrum, reiciendis facere nemo!</p>
                                    <ul class="list-inline">
                                        <li>Date: ??? </li>
                                        <li>Client: ???</li>
                                        <li>Category: ???</li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Bootstrap core JS-->
        <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script>
        <!-- Contact form JS-->
        <script src="assets/mail/jqBootstrapValidation.js"></script>
        <script src="assets/mail/contact_me.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
